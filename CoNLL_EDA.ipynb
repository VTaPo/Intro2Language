{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Phần 1: Giới thiệu về dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CoNLL 2003 là một dataset phổ biến trong lĩnh vực NLP, đặc biệt là Named Entity Recognition (NER)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Cấu trúc bộ dữ liệu\n",
    "- Bộ dữ liệu bao gồm 8 tệp chia làm 2 thứ tiếng: tiếng Anh và tiếng Đức.\n",
    "- Mỗi một ngôn ngữ gồm 1 traning file, 1 development file, 1 test file và 1 file lớn chứa dữ liệu không được gán nhãn.\n",
    "- Dữ liệu chưa được gán nhãn gồm khoảng 17 triệu token với tiếng Anh và 14 triệu token với tiếng Đức."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Quá trình xử lý\n",
    "- Model ban đầu được huấn luyện với training file, sau đó dùng dev data để tinh chỉnh tham số.\n",
    "- Tuy nhiên, khó khăn là làm sao để có thể kết hợp đồng thời cả dữ liệu chưa được gán nhãn trong quá trình.\n",
    "- Sự phân chua giữa hai tệp traning và dev cũng đã được điều chỉnh để tránh trường hợp overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Nguồn gốc của các mẫu trong dữ liệu\n",
    "- Với tiếng Anh:\n",
    "    - Ngữ liệu được lấy từ Reuters Corpus từ tháng 8/1996 đến tháng 8/1997.\n",
    "    - Traning và dev data lấy trong khoảng 10 ngày cuối tháng 8/1996.\n",
    "    - Test data lấy từ tháng 12/1996.\n",
    "    - Phần dữ liệu thô đã qua xử lý lấy từ tháng 9/1996."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Với tiếng Đức:\n",
    "    - Ngữ liệu lấy từ ECI Multilingual Text Corpus, đặc biệt là tờ báo Frankfurter Rundschau.\n",
    "    - Tất cả dữ liệu đều được lấy từ tuần cuối tháng 8/1992.\n",
    "    - Riêng dữ liệu thô lấy từ tháng 9/1992 đến tháng 12 cùng năm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Quá trình tiền xử lý dữ liệu\n",
    "- Trước khi đưa vào sử dụng, dữ liệu thô trong bộ dữ liệu CoNLL-2003 đã trải qua quá trình tiền xử lí ngôn ngữ nhằm cho mục đích NER, bao gồm tokenization, part-of-speech tagging và chunking.\n",
    "- POS tagging:\n",
    "    - Có 2 tokenizer dành riêng cho 2 ngôn ngữ tiếng Anh và tiếng Đức.\n",
    "    - Tiếng Anh: sử dụng memory-based tagger MBT.\n",
    "    - Tiếng Đức: dữ liệu được bổ đề (lemma), gắn thẻ và chia nhỏ (chunking) bằng cây quyết định Treetagger.\n",
    "- Chunking: Quá trình chia nhỏ dữ liệu, thường áp dụng trên các cụm danh từ hay các cụm từ có nhiều hàm nghĩa.\n",
    "- NER Aniotation:\n",
    "    - Tất cả các tệp được gắn nhãn của cả hai ngôn ngữ - bao gồm: tranining, dev, test - đều được xử lý hoàn toàn bằng tay tại Đại học Antwerp.\n",
    "    - Việc gắn nhãn hầu như tuân theo quy ước MUC, ngoài ra còn bổ sung thêm entity MISC để đánh dấu các tên không thuộc những trường còn lại, chủ yếu là các tính từ hay các cụm danh từ, tên sự kiện..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Phần 2: EDA**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Cài đặt các thư viện và hàm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Các thư viện cần thiết"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Các hàm hỗ trợ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Đọc các câu\n",
    "def load_sentences(filepath):\n",
    "\n",
    "    final = []\n",
    "    sentences = []\n",
    "\n",
    "    with open(filepath, 'r') as f:\n",
    "        \n",
    "        for line in f.readlines():\n",
    "            #Kiểm tra có phải là ký hiệu xuống dòng hoặc dòng đầu của file(-DOCSTART- -X- -X- O) không\n",
    "            if (line == ('-DOCSTART- -X- -X- O\\n') or line == '\\n'):\n",
    "                #Nếu trước đó có đọc được các từ trong 1 sentence thì mới append vô và reset lại sentence\n",
    "                if len(sentences) > 0:\n",
    "                    final.append(sentences)\n",
    "                    sentences = []\n",
    "            #Còn không thì đọc tiếp vào sentence\n",
    "            else:\n",
    "                l = line.split(' ')\n",
    "                sentences.append((l[0], l[3].strip('\\n')))\n",
    "    \n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Đếm số lượng câu\n",
    "def num_sentence(data):\n",
    "    num_sentences = len(data)\n",
    "    print(\"Số câu (sentence) trong tập dữ liệu là:\", num_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistic_sentence(data):\n",
    "    max_sentence_length = 0\n",
    "    min_sentence_length = float('inf')\n",
    "    total_sentence_length = 0\n",
    "    for sentence in data:\n",
    "        sentence_length = len(sentence)\n",
    "        total_sentence_length += sentence_length\n",
    "        if sentence_length > max_sentence_length:\n",
    "            max_sentence_length = sentence_length\n",
    "        if sentence_length < min_sentence_length:\n",
    "            min_sentence_length = sentence_length\n",
    "    average_sentence_length = total_sentence_length/len(data)\n",
    "    \n",
    "    print(\"Độ dài câu dài nhất:\", max_sentence_length )\n",
    "    print(\"Độ dài câu ngắn nhất:\", min_sentence_length)\n",
    "    print(\"Độ dài trung bình của các câu:\", average_sentence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_plot(df, title):\n",
    "    count_entity = df['Entity'].value_counts()\n",
    "\n",
    "    fig = px.bar(y=count_entity.values, \n",
    "             x=count_entity.index, \n",
    "             color = count_entity.index,\n",
    "             color_discrete_sequence=['#26784A','#74274E'],\n",
    "             text=count_entity.values,\n",
    "             title= title,\n",
    "             template= 'plotly_dark')\n",
    "\n",
    "    fig.update_traces(width=0.4)\n",
    "    fig.update_layout(\n",
    "        xaxis_title=\"Entity\",\n",
    "        yaxis_title=\"count\",\n",
    "        font = dict(size=17,family=\"Franklin Gothic\"))\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram(df, title):\n",
    "    fig=px.histogram(df,x=\"Entity\" ,title=title, color_discrete_sequence=px.colors.qualitative.Prism)\n",
    "    fig.update_layout(template=\"plotly_dark\",)\n",
    "    fig.update_layout(title_font_size=25)\n",
    "    fig.update_traces(marker=dict(color='blue', opacity=0.7), textposition='outside', texttemplate='%{y}')\n",
    "    fig.update_layout(\n",
    "        width=800, \n",
    "        height=700 \n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentEntity(filepath):\n",
    "    sentences = load_sentences(filepath)\n",
    "    total_token_percentages = {}\n",
    "    total_sentences = len(sentences)\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        token_counts = {}\n",
    "        total_tokens = 0\n",
    "        for word in sentence: \n",
    "            token = word[1]\n",
    "            if token in token_counts:\n",
    "                token_counts[token]+=1\n",
    "            else:\n",
    "                token_counts[token]=1\n",
    "            total_tokens+=1\n",
    "        token_percentages = {token: count / total_tokens * 100 for token, count in token_counts.items()}\n",
    "        for token,percentage in token_percentages.items():\n",
    "            if token in total_token_percentages:\n",
    "                total_token_percentages[token] += percentage\n",
    "            else:\n",
    "                total_token_percentages[token] = percentage\n",
    "    average_token_percentages = {token: percentage / total_sentences for token, percentage in total_token_percentages.items()}\n",
    "    df = pd.DataFrame(sorted(list(average_token_percentages.items())), columns=['Entity', '%'])\n",
    "    df = df.sort_values(by=['%'], ascending=False, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pie_chart(df, title):\n",
    "    a = df['%'][0]\n",
    "    b = df[\"%\"].iloc[1:19].sum()\n",
    "    data = [\n",
    "        {'Entity': 'O', '%': a},\n",
    "        {'Entity': 'Other', '%': b}\n",
    "    ]\n",
    "    df = pd.DataFrame(data)\n",
    "    fig = px.pie(values=df[\"%\"], \n",
    "                 names=df[\"Entity\"], \n",
    "                 color_discrete_sequence=[\"#CDACD1\", \"#9FD0A8\"],\n",
    "                 title= title,template='plotly_dark')\n",
    "    fig.update_layout(\n",
    "    width=800, \n",
    "    height=500  \n",
    "    )\n",
    "\n",
    "    fig.data[0].marker.line.width = 2\n",
    "    fig.data[0].marker.line.color='gray'\n",
    "    fig.update_layout(\n",
    "        font=dict(size=20,family=\"Franklin Gothic\"))\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Đọc các tập dữ liệu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Tập train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"CoNLL2003/train.txt\"\n",
    "train_sentence = load_sentences(train_path)\n",
    "columns = ['Token', 'Entity']\n",
    "token_entity_train = pd.DataFrame(columns=columns)\n",
    "for sentence in train_sentence:\n",
    "    temp_df = pd.DataFrame(sentence,columns=columns)\n",
    "    token_entity_train = pd.concat([token_entity_train,temp_df], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loại bỏ các ký tự thừa (dấu ))\n",
    "token_entity_train_clear = token_entity_train.loc[~((token_entity_train['Token'] == ',') \n",
    "                  | (['Token'] == '.') | (token_entity_train['Token'] == '\"') \n",
    "                  | (token_entity_train['Token'] == '(') | (token_entity_train['Token'] == ')')\n",
    "                  | ((token_entity_train['Token'] == ':')))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Tập test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = \"CoNLL2003/test.txt\"\n",
    "test_sentence = load_sentences(test_path)\n",
    "columns = ['Token', 'Entity']\n",
    "token_entity_test = pd.DataFrame(columns=columns)\n",
    "for sentence in test_sentence:\n",
    "    temp_df = pd.DataFrame(sentence,columns=columns)\n",
    "    token_entity_test = pd.concat([token_entity_test,temp_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loại bỏ các ký tự thừa (dấu ))\n",
    "token_entity_test_clear = token_entity_test.loc[~((token_entity_test['Token'] == ',') \n",
    "                  | (['Token'] == '.') | (token_entity_test['Token'] == '\"') \n",
    "                  | (token_entity_test['Token'] == '(') | (token_entity_test['Token'] == ')')\n",
    "                  | ((token_entity_test['Token'] == ':')))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Tập validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_path = \"CoNLL2003/valid.txt\"\n",
    "val_sentence = load_sentences(val_path)\n",
    "columns = ['Token', 'Entity']\n",
    "token_entity_val = pd.DataFrame(columns=columns)\n",
    "for sentence in val_sentence:\n",
    "    temp_df = pd.DataFrame(sentence,columns=columns)\n",
    "    token_entity_val = pd.concat([token_entity_val,temp_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loại bỏ các ký tự thừa (dấu ))\n",
    "token_entity_val_clear = token_entity_val.loc[~((token_entity_val['Token'] == ',') \n",
    "                  | (['Token'] == '.') | (token_entity_val['Token'] == '\"') \n",
    "                  | (token_entity_val['Token'] == '(') | (token_entity_val['Token'] == ')')\n",
    "                  | ((token_entity_val['Token'] == ':')))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. EDA tập train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Số lượng sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sentence(train_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Các giá trị thống kê cơ bản"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistic_sentence(train_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Entity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Tổng quan các entity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 Số lượng các token được gán I-ENTITY, B-ENTITY và O-ENTITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Số lượng các token được gắn nhãn entity (O, B, I): \",token_entity_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram(token_entity_train, \"Count Of Entities (O, B, I)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 Các entity chính"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = token_entity_train_clear.loc[~(token_entity_train_clear['Entity'] == 'O')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Số lượng các token được gắn nhãn entity (B, I): \",entities.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities[\"Entity\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram(entities, \"Count Of Entities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gộp chung B-Entity và I-Entity thành Entity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_merge = entities.copy()\n",
    "entities_merge = entities_merge.loc[entities_merge['Entity'].str.startswith('B-', na=False)]\n",
    "entities_merge['Entity'] = entities_merge['Entity'].str[2:]\n",
    "entities_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram(entities_merge, \"Count Of Entities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nhận xét:**\n",
    "- Nhìn chung các Entity xuất hiện khá đều nhau, duy nhất mỗi entity MISC có số lần xuất hiện thấp hơn các entity còn lại."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.3 Tỉ lệ trung bình của các từ thuộc nhãn O và nhãn khác O trong một câu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = percentEntity(train_path)\n",
    "cm = sns.light_palette(\"green\", as_cmap=True)\n",
    "styled_df = df.style.background_gradient(cmap=cm, subset=['%'])\n",
    "styled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pie_chart(df, \"Average ratio of O-Entity vs other Entity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Phân tích cụ thể các entity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 ORG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "organization = token_entity_train.loc[(token_entity_train['Entity'] == 'B-ORG') | (token_entity_train['Entity'] == 'I-ORG')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "organization.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_plot(organization,'ORGANIZATION')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nhận xét:**\n",
    "- Ở entity này, số lượng B_ORG gần như gấp đôi I_ORG\n",
    "- Nguyên nhân là vì trong hai ngôn ngữ tiếng Anh và tiếng Đức, tên của các tổ chức ngắn hơn và ngoài việc viết đầy đủ thì cách phổ biến hơn là viết tắt bằng cách lấy các chữ cái đầu.\n",
    "- Ví dụ:\n",
    "    - European Union -> EU\n",
    "    - United Nations -> U.N."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 PER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person = token_entity_train.loc[(token_entity_train['Entity'] == 'B-PER') | (token_entity_train['Entity'] == 'I-PER')].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_plot(person,'PERSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nhận xét:**\n",
    "- Ở entity PER, B-PER cao hơn đáng kể so với I-PER vì ngoài cách viết tên đầy đủ, thông thường dùng họ kèm theo các tiền tố như chức vị hay Mr./Mrs..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.3 LOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = token_entity_train.loc[(token_entity_train['Entity'] == 'B-LOC') | (token_entity_train['Entity'] == 'I-LOC')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_plot(location,'LOCATION')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nhận xét:**\n",
    "- Ở entity LOC, B-LOC cao hơn gấp 7 lần I-LOC.\n",
    "- Nguyên nhân khá rõ ràng, tên địa danh vùng miền trong 2 ngôn ngữ này phần lớn chỉ có 1 từ hoặc chỉ được nhắc đến ngắn gọn.\n",
    "- Ví dụ:\n",
    "    - Iraq, Chicago, Texas\n",
    "    - White House, West Virginia, Wall Street\n",
    "    - State of Ohio -> Ohio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.4 MISC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miscellaneous = token_entity_train.loc[(token_entity_train['Entity'] == 'B-MISC') | (token_entity_train['Entity'] == 'I-MISC')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miscellaneous.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_plot(miscellaneous,'MISCELLANEOUS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nhận xét:**\n",
    "- Phân loại MISC chủ yếu bao gồm các tính từ, đặc biệt là các tính từ chỉ quốc tịch, phần còn lại là các cụm danh từ.\n",
    "- Một số ví dụ điển hình cho hai nhóm trên:\n",
    "    - Italian, Japanese, European\n",
    "    - Financial Times-Stock Exchange, First Battle of the Newbury bypass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C. EDA tập test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Số lượng sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sentence(test_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Các giá trị thống kê cơ bản"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistic_sentence(test_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Entity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Tổng quan các entity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 Số lượng các token được gán I-ENTITY, B-ENTITY và O-ENTITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Số lượng các token được gắn nhãn entity (O, B, I): \",token_entity_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram(token_entity_test, \"Count Of Entities (O, B, I)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 Các entity chính"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = token_entity_test_clear.loc[~(token_entity_test_clear['Entity'] == 'O')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Số lượng các token được gắn nhãn entity (B, I): \",entities.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities[\"Entity\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram(entities, \"Count Of Entities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gộp chung B-Entity và I-Entity thành Entity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_merge = entities.copy()\n",
    "entities_merge = entities_merge.loc[entities_merge['Entity'].str.startswith('B-', na=False)]\n",
    "entities_merge['Entity'] = entities_merge['Entity'].str[2:]\n",
    "entities_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram(entities_merge, \"Count Of Entities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nhận xét:**\n",
    "- Nhìn chung các Entity xuất hiện khá đều nhau, duy nhất mỗi entity MISC có số lần xuất hiện thấp hơn các entity còn lại."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.3 Tỉ lệ trung bình của các từ thuộc nhãn O và nhãn khác O trong một câu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = percentEntity(test_path)\n",
    "cm = sns.light_palette(\"green\", as_cmap=True)\n",
    "styled_df = df.style.background_gradient(cmap=cm, subset=['%'])\n",
    "styled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pie_chart(df, \"Average ratio of O-Entity vs other Entity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Phân tích cụ thể các entity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 ORG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "organization = token_entity_test.loc[(token_entity_test['Entity'] == 'B-ORG') | (token_entity_test['Entity'] == 'I-ORG')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "organization.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_plot(organization,'ORGANIZATION')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 PER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person = token_entity_test.loc[(token_entity_test['Entity'] == 'B-PER') | (token_entity_test['Entity'] == 'I-PER')].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_plot(person,'PERSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.3 LOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = token_entity_test.loc[(token_entity_test['Entity'] == 'B-LOC') | (token_entity_test['Entity'] == 'I-LOC')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_plot(location,'LOCATION')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.4 MISC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miscellaneous = token_entity_test.loc[(token_entity_test['Entity'] == 'B-MISC') | (token_entity_test['Entity'] == 'I-MISC')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miscellaneous.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_plot(miscellaneous,'MISCELLANEOUS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D. EDA tập validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Số lượng sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sentence(val_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Các giá trị thống kê cơ bản"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistic_sentence(val_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Entity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Tổng quan các entity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 Số lượng các token được gán I-ENTITY, B-ENTITY và O-ENTITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Số lượng các token được gắn nhãn entity (O, B, I): \",token_entity_val.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram(token_entity_train, \"Count Of Entities (O, B, I)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 Các entity chính"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = token_entity_val_clear.loc[~(token_entity_val_clear['Entity'] == 'O')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Số lượng các token được gắn nhãn entity (B, I): \",entities.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities[\"Entity\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram(entities, \"Count Of Entities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gộp chung B-Entity và I-Entity thành Entity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_merge = entities.copy()\n",
    "entities_merge = entities_merge.loc[entities_merge['Entity'].str.startswith('B-', na=False)]\n",
    "entities_merge['Entity'] = entities_merge['Entity'].str[2:]\n",
    "entities_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram(entities_merge, \"Count Of Entities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.3 Tỉ lệ trung bình của các từ thuộc nhãn O và nhãn khác O trong một câu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = percentEntity(test_path)\n",
    "cm = sns.light_palette(\"green\", as_cmap=True)\n",
    "styled_df = df.style.background_gradient(cmap=cm, subset=['%'])\n",
    "styled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pie_chart(df, \"Average ratio of O-Entity vs other Entity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Phân tích cụ thể các entity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 ORG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "organization = token_entity_val.loc[(token_entity_val['Entity'] == 'B-ORG') | (token_entity_val['Entity'] == 'I-ORG')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "organization.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_plot(organization,'ORGANIZATION')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 PER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person = token_entity_val.loc[(token_entity_val['Entity'] == 'B-PER') | (token_entity_val['Entity'] == 'I-PER')].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_plot(person,'PERSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.3 LOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = token_entity_val.loc[(token_entity_val['Entity'] == 'B-LOC') | (token_entity_val['Entity'] == 'I-LOC')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_plot(location,'LOCATION')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.4 MISC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miscellaneous = token_entity_val.loc[(token_entity_val['Entity'] == 'B-MISC') | (token_entity_val['Entity'] == 'I-MISC')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miscellaneous.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_plot(miscellaneous,'MISCELLANEOUS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E. Nhận xét chung\n",
    "- Hầu hết các thực thể đều được gắn nhãn phù hợp.\n",
    "- Tỉ lệ train:test:val = 14:3:3.\n",
    "- Ưu điểm:\n",
    "    - Dataset tuân theo cách đánh giá tiêu chuẩn, dễ dàng so sánh giữa các mô hình NER khác.\n",
    "    - Bộ dữ liệu lấy từ thực tế, phù hợp với ngữ cảnh sử dụng.\n",
    "- Nhược điểm:\n",
    "    - Bộ ngữ liệu quá cũ, đều lấy từ trước năm 2000. Ở thời điểm hiện tại, tổ chức ngôn ngữ ít nhiều thay đổi do đó có khó khăn nhất định nếu sử dụng để phân tích ngôn ngữ hiện đại.\n",
    "    - Nguồn dữ liệu hạn chế do lấy từ các bài báo, văn phong và hình thức văn bản bị bó buộc.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
